head     22.3;
access   avg dmitry flerov davidov alex fox korotaev dvolodin abs;
symbols  Архыз0:1.6.1;
locks    ;
comment  @ * @;


22.3
date     90.11.12.19.17.48;  author root;  state Exp;
branches ;
next     22.2;

22.2
date     89.07.08.18.33.52;  author avg;  state Exp;
branches ;
next     22.1;

22.1
date     89.04.12.15.34.18;  author korotaev;  state Exp;
branches ;
next     22.0;

22.0
date     89.03.30.16.32.59;  author korotaev;  state Exp;
branches ;
next     1.9;

1.9
date     89.03.04.14.23.07;  author abs;  state Exp;
branches ;
next     1.8;

1.8
date     89.01.20.20.20.43;  author abs;  state Exp;
branches ;
next     1.7;

1.7
date     89.01.07.20.52.14;  author korotaev;  state Exp;
branches ;
next     1.6;

1.6
date     88.11.02.12.47.27;  author dvolodin;  state Exp;
branches ;
next     1.5;

1.5
date     88.03.23.13.36.14;  author korotaev;  state Exp;
branches ;
next     1.4;

1.4
date     87.04.18.14.21.52;  author avg;  state Exp;
branches ;
next     1.3;

1.3
date     87.01.22.08.33.13;  author alex;  state Stab;
branches ;
next     1.2;

1.2
date     87.01.19.22.52.11;  author alex;  state Exp;
branches ;
next     1.1;

1.1
date     86.04.19.15.51.50;  author avg;  state Stab;
branches ;
next     ;


desc
@Ядро системы.  Машинно-независимая часть.
@


22.3
log
@Новые вещи для СМ1425 и перемещение include.
@
text
@/*
 * $Log:	slp.c,v $
 * Revision 22.2  89/07/08  18:33:52  avg
 * Правлена ошибка by korotaev (see diff 1.4 --> 1.5): 
 * дважды вызывался SETRQ.
 * Ошибка найдена при переносе на 8086.
 * 
 * Revision 22.1  89/04/12  15:34:18  korotaev
 * "param.h" ==> <sys/param.h>
 *
 * Revision 22.0  89/03/30  16:32:59  korotaev
 * Begining DEMOS 2.2.
 *
 * Revision 1.9  89/03/04  14:23:07  abs
 * в sleep добавлен флаг PCATCH a la systemV
 *
 * Revision 1.8  89/01/20  20:20:43  abs
 * new malloc (mexpand)
 *
 * Revision 1.8  89/01/16  11:54:26  abs
 * Изменен механизм расширения сегмента data. Если после него есть свободное
 * место - оно присоединяется (и не надо переписывать сегмент в новое место
 * как было раньше).
 *
 * Revision 1.7  89/01/07  20:52:14  korotaev
 * Слияние с исправлениями насчет FIFO, +fcntl, + разные режимы открытия
 *
 * (from VAX/UTS SV.2)
 *
 * Revision 1.6  88/11/02  12:47:27  dvolodin
 * *** empty log message ***
 *
 * Revision 1.5  88/03/23  13:36:14  korotaev
 * Состояние после слияния с АЗЛК, Э-85 и Бурковским планировщиком
 *
 * Revision 1.4  87/04/18  14:21:52  avg
 * Изменения приоритетов by alex.
 *
 * Revision 1.3  87/01/22  08:33:13  alex
 * Правки под сохранение сегмента text в памяти после выкачки процесса.
 * + введен параметр FXMETER для измерения эффекта от этого нововведения.
 *
 * Revision 1.2  87/01/19  22:52:11  alex
 * Убран spl6() из цикла по таблице процессов в
 * задаче подкачки. Это можно делать, так как если даже
 * и отработает wakeup во время поиска, ничего страшного
 * не случится.
 *
 * Revision 1.1  86/04/19  15:51:50  avg
 * Initial revision
 *
 */

#define IPK_MEXPAND
#include <sys/param.h>
#include <sys/systm.h>
#include <sys/dir.h>
#include <sys/user.h>
#include <sys/proc.h>
#include <sys/text.h>
#include "../include/map.h"
#include <sys/file.h>
#include <sys/inode.h>
#include "../include/buf.h"
#include <sys/seg.h>
#ifdef  UCB_METER
#include <sys/vm.h>
#endif
#include "../include/inline.h"

#ifdef  UCB_FRCSWAP
extern  int     idleflg ;       /* If set, allow incore forks and expands */
				/* Set before idle(), cleared in clock.c */
#endif

#ifdef  CGL_RTP
int     wantrtp;        /* Set when the real-time process is runnable */
#endif

#ifdef SCHED
#define TTIINC          6       /* tty input increment */
#define TTOINC          4       /* tty output increment */
#define OTHINC          2       /* increment for other sleeps */

short curlevel = 0;
#define QUANTUM 2       /* CPU quantum -- must be <= 7 to avoid overflow */
short quantum = QUANTUM;
#endif SCHED

#ifdef  SMALL
#define SQSIZE 010      /* Must be power of 2 */
#else
#define SQSIZE 0100     /* Must be power of 2 */
#endif

#define HASH(x) (( (int) x >> 5) & (SQSIZE-1))
struct  proc    *slpque[SQSIZE];

/*
 * Give up the processor till a wakeup occurs
 * on chan, at which time the process
 * enters the scheduling queue at priority pri.
 * The most important effect of pri is that when
 * pri<=PZERO a signal cannot disturb the sleep;
 * if pri>PZERO signals will be processed.
 * Callers of this routine must be prepared for
 * premature return, and check that the reason for
 * sleeping has gone away.
 */

/* Возврат из sleep:
 *                 sleep
 *   pri<= PZERO          pri > PZERO
 *  не прерывается по    прерывается по
 *  сигналам             сигналам
 *  wakeup           wakeup       signal
 *   return 0        return 0       |
 *                             PCATCH   noPCATCH
 *                             return 1    resume
 */
sleep(chan, pri)
caddr_t chan;
{
	register struct proc *rp;
	register struct proc **hp;
	register s;
	register retintr;       /* не 0, если есть флаг PCATCH */

	rp = u.u_procp;
	retintr = pri & PCATCH ;   pri &= PMASK;
	s = spl6();
#ifdef SCHED
	if (chan==0)
#else SCHED
	if (chan==0 || rp->p_stat != SRUN)
#endif SCHED
		panic("sleep");
	rp->p_wchan = chan;
#ifdef  UCB_METER
	rp->p_slptime = 0;
#endif
#ifndef SCHED
	rp->p_pri = pri;
#endif  SCHED
	hp = &slpque[HASH(chan)];
	rp->p_link = *hp;
	*hp = rp;
	if(pri > PZERO) {
#ifdef SCHED
		rp->p_stat = SWAIT;
#endif SCHED
		if(ISSIG(rp)) {
			if (rp->p_wchan)
				unsleep(rp);
			rp->p_stat = SRUN;
			(void) _spl0();
			goto psig;
		}
		if (rp->p_wchan == 0)
			goto out;
#ifndef  SCHED
		rp->p_stat = SSLEEP;
#endif  SCHED
		(void) _spl0();
		if(runin != 0) {
			runin = 0;
			wakeup((caddr_t)&runin);
		}
		swtch();
		if(ISSIG(rp))
			goto psig;
	} else {
		rp->p_stat = SSLEEP;
		(void) _spl0();
		swtch();
	}
out:
	splx(s);
	return 0;       /* normal (wakeuped) */

	/*
	 * If priority was low (>PZERO) and
	 * there has been a signal,
	 * execute non-local goto to
	 * the qsav location.
	 * (see trap.c)
	 */
psig:
	if( retintr ){
		splx(s);
		return 1;       /* signalled */
	}
	/* else restart */
	resume(u.u_procp->p_addr, u.u_qsav);
	/*NOTREACHED*/
}


/*
 * Remove a process from its wait queue
 */
unsleep(p)
register struct proc *p;
{
	register struct proc **hp;
	register s;

	s = spl6();
	if (p->p_wchan) {
		hp = &slpque[HASH(p->p_wchan)];
		while (*hp != p)
			hp = &(*hp)->p_link;
		*hp = p->p_link;
		p->p_wchan = 0;
	}
	splx(s);
}


/*
 * Wake up all processes sleeping on chan.
 */

wakeup(chan)
register caddr_t chan;
{
	register struct proc *p, **q;
	struct proc **h;
	int i, s;
#ifndef NOKA5
	mapinfo map;

	/*
	 * Since we are called at interrupt time, must insure normal
	 * kernel mapping to access proc.
	 */
	savemap(map);
#endif
	s = spl6();
	h = &slpque[HASH(chan)];
restart:
	for (q = h; p = *q; ) {
		if (p->p_stat != SSLEEP && p->p_stat != SSTOP
#ifdef  SCHED
	     && p->p_stat != SWAIT  && p->p_stat != SRUN
#endif  SCHED
	       )
			panic("wakeup");
		if (p->p_wchan==chan) {
			p->p_wchan = 0;
			*q = p->p_link;
#ifdef  UCB_METER
			p->p_slptime = 0;
#endif
			if (p->p_stat == SSLEEP
#ifdef  SCHED
			 || p->p_stat == SWAIT
#endif  SCHED
			 ) {
				setrun(p);
				goto restart;
			}
		} else
			q = &p->p_link;
	}
	splx(s);
#ifndef NOKA5
	restormap(map);
#endif
}


#if defined(DIAGNOSTIC) || defined(SCHED)
#  define SETRQ(p) setrq(p)
#else
#  define SETRQ(p) ((p->p_link = runq) , (runq=p))
#endif
#ifdef SCHED
/*
 * SETRQ -- called only from within this source file, SETRQ inserts
 * a specified process into the "ready" process queue used by the
 * CPU dispatcher "swtch".  Sorting into the ready list is based on
 * the priority level p_level of the process.  The flag argument
 * determines whether the process is put at the head or the tail
 * of the processes at its level (head if nonzero).
 */

setrq(p,flag)
register struct proc *p;
int flag;       /* if nonzero, insert at head */
{
	register struct proc *q, *ip;   /* ip is "insertion point" */
	int s;

	s = spl6();

	ip = NULL;
	p->p_stat =SRUN;
	/* process p will be inserted before the first process q which */
	/* satisfies the necessary condition (q worse prio than p)     */
/*      for(q = runq; q != NULL; q = q->p_link){
*/      q = runq;
	do {
		if (q == NULL)
			break;
		if(q->p_level < p->p_level ||(flag && q->p_level == p->p_level))
			break;
		ip = q;
		q = q->p_link;
	} while (q != runq);

	if(ip == NULL){ /* insert at start of list */
		p->p_link = runq;
		runq = p;
	}
	else { /* general insertion case */
		p->p_link = ip->p_link; /* save rest of list */
		ip->p_link = p;
	}

	if(p->p_level > curlevel)
		runrun++;       /* this line implements preemptive scheduling */
	splx(s);
}
#else SCHED

/*
 * When you are sure that it
 * is impossible to get the
 * 'proc on q' diagnostic, the
 * diagnostic loop can be removed.
 */
setrq(p)
struct proc *p;
{
	register struct proc *q;
	register s;

	s = spl6();
#ifdef  DIAGNOSTIC
	for(q=runq; q!=NULL; q=q->p_link)
		if(q == p) {
			printf("proc on q\n");
			goto out;
		}
#endif
	p->p_link = runq;
	runq = p;
out:
	splx(s);
}
#endif SCHED

/*
 * Remove runnable job from run queue.
 * This is done when a runnable job is swapped
 * out so that it won't be selected in swtch().
 * It will be reinserted in the runq with setrq
 * when it is swapped back in.
 */
remrq(p)
	register struct proc *p;
{
	register struct proc *q;
	int s;

	s = spl6();
	if (p == runq)
		runq = p->p_link;
	else {
		for (q = runq; q; q = q->p_link)
			if (q->p_link == p) {
				q->p_link = p->p_link;
				goto done;
			}
		panic("remque");
done:
		;
	}
	splx(s);
}

/*
 * Set the process running;
 * arrange for it to be swapped in if necessary.
 */
setrun(p)
register struct proc *p;
{
	register s;

	s = spl6();
	switch (p->p_stat) {

#ifdef SCHED
	case SWAIT:
#endif SCHED
	case SSTOP:
	case SSLEEP:
		unsleep(p);             /* e.g. when sending signals */
		break;

	case SIDL:
		break;

	default:
		panic("setrun");
	}
	p->p_stat = SRUN;
#ifdef SCHED
	setlev(p,1);
	setrq(p,0);
#else
	if (p->p_flag & SLOAD)
		SETRQ(p);
#endif SCHED
	splx(s);

#ifdef  CGL_RTP
	if (p == rtpp) {
		wantrtp++;
		runrun++;
	}
	else
#endif
#ifndef SCHED
		if (p->p_pri < curpri)
			runrun++;
#endif SCHED
	if(runout != 0 && (p->p_flag&SLOAD) == 0) {
		runout = 0;
		wakeup((caddr_t)&runout);
	}
}

#ifdef SCHED
setlev(p,flag)
register struct proc *p;
int flag;
{
	register i;
	/* adjust level if necessary */
	if((i = p->p_baslev) < RTLEVEL){
		if(p->p_level > i)
			p->p_level--;
		if(p->p_sflag & STTYIN)
			i += TTIINC;
		else if(p->p_sflag & STTYOUT)
			i += TTOINC;
		else if (flag)
			i += OTHINC;
		if(i >= RTLEVEL)
			i = RTLEVEL - 1;
		if(i > p->p_level)
			p->p_level = i;
	}
	p->p_quant = 0;
	p->p_sflag &= ~ (STTYIN | STTYOUT);
}
#else

/*
 * Set user priority.
 * The rescheduling flag (runrun)
 * is set if the priority is better
 * than the currently running process.
 */
setpri(pp)
register struct proc *pp;
{
	register p;

	p = ((pp->p_cpu & 0377) / 16) + PUSER + pp->p_nice - NZERO;
	if(p > 127)
		p = 127;
	if(p < curpri)
		runrun++;
	pp->p_pri = p;
	return(p);
}
#endif SCHED
/*
 * The main loop of the scheduling (swapping)
 * process.
 * The basic idea is:
 *  see if anyone wants to be swapped in;
 *  swap out processes until there is room;
 *  swap him in;
 *  repeat.
 * The runout flag is set whenever someone is swapped out.
 * Sched sleeps on it awaiting work.
 *
 * Sched sleeps on runin whenever it cannot find enough
 * core (by swapping out or otherwise) to fit the
 * selected swapped process.  It is awakened when the
 * core situation changes and in any case once per second.
 */
#ifdef SCHED
sched()
{
	register struct proc *p, *rp, *q;
	int maxsize, desperate;

	for(;;){        /* keep loading processes !!! */
		/*
		 * Find process to swap in; the eligible process is the first
		 * one in the "ready" list which is not loaded at present.
		 */
		spl6();
		for (p = runq; p != NULL; p = p->p_link){
			if((p->p_stat == SRUN) && (p->p_flag & SLOAD) == 0)
				break;
		}
		if (p == NULL){
			runout++;
			sleep((caddr_t)&runout, PSWP);
			continue;
		}
		spl0();

		/* if there is enough free core, swap in the process */

		if (swapin(p)){
			continue;
		}

		/* find core by out-swapping largest eligible process */
		spl6();
		q = NULL;
		for(desperate = 0; q == NULL && desperate <= 1; desperate++){
			maxsize = -1;
			for (rp = &proc[0]; rp < maxproc; rp++) {
				if(swapok(p,rp,desperate)){
#ifdef  VIRUS_VFORK
				   if (maxsize < rp->p_dsize + rp->p_ssize) {
					q = rp;
					maxsize = rp->p_dsize + rp->p_ssize;
				   }
#else
				    if (maxsize < rp->p_size) {
					q = rp;
					maxsize = rp->p_size;
				    }
#endif
				}
			}
		}
		if(q != NULL){
			spl0();
			q->p_flag &= ~SLOAD;
#ifdef  VIRUS_VFORK
			(void) xswap(q, X_FREECORE, X_OLDSIZE, X_OLDSIZE);
#else
			(void) xswap(q, X_FREECORE, X_OLDSIZE);
#endif
		}
		else {
			runin++;
			sleep((caddr_t)&runin, PSWP);
		}
	}
}
#else
#define PRISIZE 128
sched()
{
	register struct proc *rp, *p;
	register outage, inage;
	size_t maxsize;
	size_t nmaxsize;
	/*
	 * find user to swap in;
	 * of users ready, select one out longest
	 */

loop:
	(void) _spl0();
/*      (void) _spl6();  Стояло из опасения, что выражение может
			 при изменение аргументов вычислиться неверно
			 В данном случае это не так */
	outage = -20000;
	for (rp = &proc[0]; rp <= maxproc; rp++)
#ifdef  VIRUS_VFORK
	/* always bring in parents ending a vfork, to avoid deadlock */
	if (rp->p_stat==SRUN && (rp->p_flag&SLOAD)==0 &&
	    ((rp->p_time - (rp->p_nice-NZERO)*8 > outage)
	    || (rp->p_flag & SVFPARENT)))
#else
	if (rp->p_stat==SRUN && (rp->p_flag&SLOAD)==0 &&
	    rp->p_time - (rp->p_nice-NZERO)*8 > outage)
#endif
		{
		p = rp;
		outage = rp->p_time - (rp->p_nice-NZERO)*8;
#ifdef  VIRUS_VFORK
		if (rp->p_flag & SVFPARENT)
			break;
#endif
	}
	/*
	 * If there is no one there, wait.
	 */
	if (outage == -20000) {
		_spl6();
		runout++;
		sleep((caddr_t)&runout, PSWP);
		(void) _spl0();
		goto loop;
	}

	/*
	 * See if there is core for that process;
	 * if so, swap it in.
	 */

	if (swapin(p))
		goto loop;

	/*
	 * none found.
	 * look around for core.
	 * Select the largest of those sleeping
	 * at bad priority; if none, select the oldest.
	 */
/*        (void) _spl6();       См. комм. выше */
	p = NULL;
	maxsize = 0;
	inage = -1;
	for (rp = &proc[1]; rp <= maxproc; rp++) {
		if (rp->p_stat==SZOMB
		 || (rp->p_flag&(SSYS|SLOCK|SULOCK|SLOAD))!=SLOAD)
			continue;
		if (rp->p_textp && rp->p_textp->x_flag&XLOCK)
			continue;
		if (rp->p_stat==SSLEEP&&rp->p_pri>=PZERO || rp->p_stat==SSTOP) {
#ifdef  VIRUS_VFORK
			if (maxsize <
			   (nmaxsize = rp->p_dsize + rp->p_ssize +
			    ((rp->p_textp && rp->p_textp->x_count == 1)?
				rp->p_textp->x_size:0)+
				rp->p_time*PRISIZE)) {
				p = rp;
				maxsize = nmaxsize;
			}
#else
			if (maxsize < rp->p_size) {
				p = rp;
				maxsize = rp->p_size;
			}
#endif
		} else if (maxsize==0 && (rp->p_stat==SRUN||rp->p_stat==SSLEEP)
#ifdef  CGL_RTP
		    /*
		     * Can't swap processes preempted in copy/clear.
		     */
		    && (rp->p_pri > PRTP + 1)
#endif
		    ) {
			if (rp->p_time+rp->p_nice-NZERO > inage) {
				p = rp;
				inage = rp->p_time+rp->p_nice-NZERO;
			}
		}
	}
	/* _spl0(); */
	/*
	 * Swap found user out if sleeping at bad pri,
	 * or if he has spent at least 2 seconds in core and
	 * the swapped-out process has spent at least 3 seconds out.
	 * Otherwise wait a bit and try again.
	 */
	if (maxsize>0 || (outage>=3 && inage>=2)) {
		(void) _spl6();
		p->p_flag &= ~SLOAD;
		if(p->p_stat == SRUN)
			remrq(p);
		(void) _spl0();
#ifdef  VIRUS_VFORK
		(void) xswap(p, X_FREECORE, X_OLDSIZE, X_OLDSIZE);
#else
		(void) xswap(p, X_FREECORE, X_OLDSIZE);
#endif
		goto loop;
	}
	(void) _spl6();
	runin++;
	sleep((caddr_t)&runin, PSWP);
	(void) _spl0();
	goto loop;
}
#endif SCHED
#ifdef SCHED
/*
 * SWAPOK is a predicate (truth-valued function) used to determine the
 * desirability of swapping process 'loser' in order to bring in process
 * 'winner'.  The 'desperate' flag captures the distinction between
 * 'easy core' and 'hard core'.
 */

int
swapok(winner,loser,desperate)
register struct proc *winner, *loser;
int desperate;
{
	register struct proc *p;

	if ((loser->p_flag & (SSYS|SLOCK|SULOCK|SLOAD)) != SLOAD)
		return(0);
	/* don't swap out a process which is at "real-time" priority level */
	if(loser->p_level >= RTLEVEL)
		return(0);
	/* avoid deadlocks -- don't swap out process with locked text */
	if(loser->p_textp && (loser->p_textp->x_flag & XLOCK))
		return(0);
	switch(loser->p_stat){
	case SSTOP:
	case SWAIT:
		break;
	case SRUN:
		if(!desperate)
			return(0);
		if(loser->p_sflag & SEXEC){
			return(0);      /* avoid swapping an EXECing proc */
		}
		/* make sure that winner is higher priority than loser */
		if(winner->p_level < loser->p_level)
			return(0);
		if(winner->p_level == loser->p_level){
			p = winner;
			while(p && p != loser && p->p_level == winner->p_level)
				p = p->p_link;
			if(p != loser)
				return(0);
		}
		break;
	case SSLEEP:
		if(!desperate)
			return(0);
		if(loser->p_sflag & SEXEC){
			return(0);      /* avoid swapping an EXECing proc */
		}
		break;
	default:
		return(0);
	}
	/* if loser has been loaded less than time-to-swap, or */
	/* loser has never been scheduled to run since being loaded */
	return(1);
}
#endif SCHED
/*
 * Swap a process in.
 * Allocate data and possible text separately.
 * It would be better to do largest first.
 */
#ifdef  VIRUS_VFORK
/*
 * Text, data, stack and u. are allocated in that order,
 * as that is likely to be in order of size.
 */
#endif
swapin(p)
register struct proc *p;
{
#ifdef  VIRUS_VFORK
	register struct text *xp;
	memaddr a[3];
	register memaddr x = NULL;
	smeter(p);
	/*
	 *  Malloc the text segment first, as it tends to be largest.
	 */
	if (xp = p->p_textp) {
		xlock(xp);
		xmeter(xp);
		if (xp->x_caddr == 0) {
			if ((x = malloc(coremap, xp->x_size)) == NULL) {
				xunlock(xp);
				return(0);
			}
		}
	}
	if (malloc3(coremap, p->p_dsize, p->p_ssize, USIZE, a) == NULL) {
		if (x)
			mfree(coremap, xp->x_size, x);
		if (xp)
			xunlock(xp);
		return(0);
	}
	if (x) {
		xp->x_caddr = x;
		if ((xp->x_flag & XLOAD) == 0)
			swap(xp->x_daddr, x, xp->x_size, B_READ);
	}
	if (xp) {
		xp->x_ccount++;
		xunlock(xp);
	}
	if (p->p_dsize) {
		swap(p->p_daddr, a[0], p->p_dsize, B_READ);
		mfree(swapmap, ctod(p->p_dsize), p->p_daddr);
	}
	if (p->p_ssize) {
		swap(p->p_saddr, a[1], p->p_ssize, B_READ);
		mfree(swapmap, ctod(p->p_ssize), p->p_saddr);
	}
	swap(p->p_addr, a[2], USIZE, B_READ);
	mfree(swapmap, ctod(USIZE), p->p_addr);
	p->p_daddr = a[0];
	p->p_saddr = a[1];
	p->p_addr = a[2];

#else   VIRUS_VFORK
	register struct text *xp;
	register int a;
	register unsigned x = 0;

	if ((a = malloc(coremap, p->p_size)) == NULL)
		return(0);
	if (xp = p->p_textp) {
		xlock(xp);
		xmeter(xp);
		if (xp->x_caddr == 0) {
			if ((x = malloc(coremap, xp->x_size)) == NULL)
				{
				xunlock(xp);
				mfree(coremap, p->p_size, a);
				return(0);
			}
			xp->x_caddr = x;
			if ((xp->x_flag & XLOAD)==0)
				swap(xp->x_daddr, x, xp->x_size, B_READ);
		}
		xp->x_ccount++;
		xunlock(xp);
	}
	swap(p->p_addr, a, p->p_size, B_READ);
	mfree(swapmap, ctod(p->p_size), p->p_addr);
	p->p_addr = a;
#endif  VIRUS_VFORK

#ifndef SCHED
	if (p->p_stat == SRUN)
		setrq(p);
#endif SCHED
	p->p_flag |= SLOAD;
#ifdef SCHED
	p->p_quant = 0;
#else  SCHED
	p->p_time = 0;
#endif SCHED
	return(1);
}

/*
 * put the current process on
 * the queue of running processes and
 * call the scheduler.
 */
qswtch()
{
#ifdef SCHED
	register struct proc *p;
	register int f = 0;     /* setrq flag */
	register int i;

	p = u.u_procp;

	if(quantum <= 0)       /* end-of-quantum processing */
		setlev(p,0);
	else {                  /* process preempted by higher level process */
		p->p_quant = quantum;
		f++;    /* insert process at head of level subqueue */
	}
	setrq(p,f);
#else
	setrq(u.u_procp);
#endif SCHED
	swtch();
}

/*
 * This routine is called to reschedule the CPU.
 * if the calling process is not in the RUN state,
 * arrangements for it to restart must have
 * been made elsewhere, usually by calling via sleep.
 * There is a race here. A process may become
 * ready after it has been examined.
 * In this case, idle() will be called and
 * will return in at most 1hz time.
 * i.e. it's not worth putting an spl() in.
 */
swtch()
{
	register n;
	register struct proc *p, *q;
	struct proc *pp, *pq;

#if defined(DIAGNOSTIC) && !defined(NOKA5)
	extern struct buf *hasmap;
	if(hasmap != (struct buf *)0)
		panic("swtch hasmap");
#endif
	/*
	 * If not the idle process, resume the idle process.
	 */
	if (u.u_procp != &proc[0]) {
		if (save(u.u_rsav)) {
			sureg();
			return;
		}
#ifndef NONFP
		if (u.u_fpsaved==0) {
			savfp(&u.u_fps);
			u.u_fpsaved = 1;
		}
#endif
		resume(proc[0].p_addr, u.u_qsav);
	}
	/*
	 * The first save returns nonzero when proc 0 is resumed
	 * by another process (above); then the second is not done
	 * and the process-search loop is entered.
	 *
	 * The first save returns 0 when swtch is called in proc 0
	 * from sched().  The second save returns 0 immediately, so
	 * in this case too the process-search loop is entered.
	 * Thus when proc 0 is awakened by being made runnable, it will
	 * find itself and resume itself at rsav, and return to sched().
	 */
	if (save(u.u_qsav)==0 && save(u.u_rsav))
		return;
#ifdef  UCB_METER
	cnt.v_swtch++;
#endif
loop:
	(void) _spl6();
	runrun = 0;
#ifdef  CGL_RTP
	/*
	 * Test for the presence of a "real time process".
	 * If there is one and it is runnable, give it top
	 * priority.
	 */
	if ((p=rtpp) && p->p_stat==SRUN && (p->p_flag&SLOAD)) {
		pq = NULL;
		for (q=runq; q!=NULL; q=q->p_link) {
			if (q == p)
				break;
			pq = q;
		}
		if (q == NULL)
			panic("rtp not found\n");       /* "cannot happen" */
		n = PRTP;
		wantrtp = 0;
		goto runem;
	}
#endif
	q = NULL;
#ifdef SCHED
	for(p = runq; p != NULL && (p->p_flag & SLOAD) == 0; p = p->p_link){
		q = p;  /* update predecessor */
	}
#else
	pp = NULL;
	n = 128;
	/*
	 * Search for highest-priority runnable process
	 */
	for(p=runq; p!=NULL; p=p->p_link) {
		if((p->p_stat==SRUN) && (p->p_flag&SLOAD)) {
			if(p->p_pri < n) {
				pp = p;
				pq = q;
				n = p->p_pri;
			}
		}
		q = p;
	}
	/*
	 * If no process is runnable, idle.
	 */
	p = pp;
#endif SCHED
	if(p == NULL) {
#ifdef  UCB_FRCSWAP
		idleflg++;
#endif
		idle();
		goto loop;
	}
#ifdef SCHED
/*      else
		if(p->p_stat != SRUN)
			panic("not ready");
*/
#else  SCHED
#ifdef  CGL_RTP
runem:
#endif
	q = pq;
#endif SCHED
	if(q == NULL)
		runq = p->p_link;
	else
		q->p_link = p->p_link;
#ifdef SCHED
	p->p_link = NULL;
	n = p->p_level;
	curlevel = n;
	if(p->p_quant > 0)      /* last quantum partially used */
		quantum = p->p_quant;
	else {
		if(n >= RTLEVEL)
			quantum = QUANTUM;
		else
			quantum = QUANTUM * (RTLEVEL - n);
	}

#else
	curpri = n;
#endif SCHED
	(void) _spl0();
	/*
	 * The rsav (ssav) contents are interpreted in the new address space
	 */
	n = p->p_flag&SSWAP;
	p->p_flag &= ~SSWAP;
	resume(p->p_addr, n? u.u_ssav: u.u_rsav);
}

/*
 * Create a new process-- the internal version of
 * sys fork.
 * It returns 1 in the new process, 0 in the old.
 */
#ifdef  VIRUS_VFORK
newproc(isvfork)
#else
newproc()
#endif
{
	int a1, a2;
	register struct proc *rpp, *rip;
	register n;
#ifdef  VIRUS_VFORK
	unsigned a[3];
#endif

	rpp = NULL;
	/*
	 * First, just locate a slot for a process
	 * and copy the useful info from this process into it.
	 * The panic "cannot happen" because fork has already
	 * checked for the existence of a slot.
	 */
retry:
	mpid++;
	if(mpid >= 30000)
		mpid = 1;
	for(rip = proc; rip < procNPROC; rip++) {
		if(rip->p_stat == NULL && rpp==NULL)
			rpp = rip;
		if (rip->p_pid==mpid || rip->p_pgrp==mpid)
			goto retry;
	}
	if (rpp == NULL)
		panic("no procs");

	/*
	 * make proc entry for new proc
	 */

	rip = u.u_procp;
	rpp->p_clktim = 0;
	rpp->p_stat = SIDL;
	rpp->p_flag = SLOAD | (rip->p_flag & (SDETACH|SNUSIG));
	rpp->p_pptr = rip;
	rpp->p_siga0 = rip->p_siga0;
	rpp->p_siga1 = rip->p_siga1;
	rpp->p_cursig = 0;
	rpp->p_wchan = 0;
	rpp->p_uid = rip->p_uid;
	rpp->p_pgrp = rip->p_pgrp;
#ifdef SCHED
	rpp->p_quant = 0;
	rpp->p_sflag = 0;
	rpp->p_baslev = rip->p_baslev;
	rpp->p_level = (rpp->p_baslev>=RTLEVEL)?rpp->p_baslev:(RTLEVEL-1);
	rpp->p_link = NULL;
#else
	rpp->p_nice = rip->p_nice;
	rpp->p_time = 0;
	rpp->p_cpu = 0;
#endif SCHED
	rpp->p_textp = rip->p_textp;
	rpp->p_pid = mpid;
	rpp->p_ppid = rip->p_pid;
#ifdef  UCB_METER
	rpp->p_slptime = 0;
#endif
	if (rpp > maxproc)
		maxproc = rpp;

	/*
	 * make duplicate entries
	 * where needed
	 */

	for(n=0; n<NOFILE; n++)
		if(u.u_ofile[n] != NULL)
			u.u_ofile[n]->f_count++;
#ifdef  VIRUS_VFORK
	if ((rip->p_textp != NULL) && !isvfork)
#else
	if(rip->p_textp != NULL)
#endif
	{
		rip->p_textp->x_count++;
		rip->p_textp->x_ccount++;
	}
	u.u_cdir->i_count++;
	if (u.u_rdir)
		u.u_rdir->i_count++;
	/*
	 * When the resume is executed for the new process,
	 * here's where it will resume.
	 */
	if (save(u.u_ssav)) {
		sureg();
		return(1);
	}
	/*
	 * Partially simulate the environment
	 * of the new process so that when it is actually
	 * created (by copying) it will look right.
	 */
	u.u_procp = rpp;

#ifdef  VIRUS_VFORK
	rpp->p_dsize = rip->p_dsize;
	rpp->p_ssize = rip->p_ssize;
	rpp->p_daddr = rip->p_daddr;
	rpp->p_saddr = rip->p_saddr;
	a1 = rip->p_addr;
	if (isvfork)
		a[2] = malloc(coremap,USIZE);
	else {
		/*
		 * malloc3() will set a[2] to NULL on failure.
		 */
#ifdef  UCB_FRCSWAP
		a[2] = NULL;
		if (idleflg)
#endif
			(void) malloc3(coremap,rip->p_dsize,rip->p_ssize,USIZE,a);
	}
	/*
	 * If there is not enough core for the
	 * new process, swap out the current process to generate the
	 * copy.
	 */
	if(a[2] == NULL) {
		rip->p_stat = SIDL;
		rpp->p_addr = a1;
		rpp->p_stat = SRUN;
		(void) xswap(rpp, X_DONTFREE, X_OLDSIZE, X_OLDSIZE);
		rip->p_stat = SRUN;
		u.u_procp = rip;
	} else {
		/*
		 * There is core, so just copy.
		 */
		rpp->p_addr = a[2];
#ifdef  CGL_RTP
		/*
		 * Copy is now a preemptable kernel process.
		 * The u. area is non-reentrant so copy it first
		 * in non-preemptable mode.
		 */
		copyu(rpp->p_addr);
#else
		copy(a1, rpp->p_addr, USIZE);
#endif
		u.u_procp = rip;
		if (isvfork == 0) {
			rpp->p_daddr = a[0];
			copy(rip->p_daddr, rpp->p_daddr, rpp->p_dsize);
			rpp->p_saddr = a[1];
			copy(rip->p_saddr, rpp->p_saddr, rpp->p_ssize);
		}
		(void) _spl6();
		rpp->p_stat = SRUN;
#ifndef SCHED
		SETRQ(rpp);
#endif SCHED
		(void) _spl0();
	}
#ifdef SCHED
	setrq(rpp, 0);
#endif SCHED
	rpp->p_flag |= SSWAP;
	if (isvfork) {
		/*
		 *  Set the parent's sizes to 0, since the child now
		 *  has the data and stack.
		 *  (If we had to swap, just free parent resources.)
		 *  Then wait for the child to finish with it.
		 */
		if (a[2] == NULL) {
			mfree(coremap,rip->p_dsize,rip->p_daddr);
			mfree(coremap,rip->p_ssize,rip->p_saddr);
		}
		rip->p_dsize = 0;
		rip->p_ssize = 0;
		rip->p_textp = NULL;
		rpp->p_flag |= SVFORK;
		rip->p_flag |= SVFPARENT;
		while (rpp->p_flag & SVFORK)
			sleep((caddr_t)rpp,PSWP+1);
		if ((rpp->p_flag & SLOAD) == 0)
			panic("newproc vfork");
		u.u_dsize = rip->p_dsize = rpp->p_dsize;
		rip->p_daddr = rpp->p_daddr;
		rpp->p_dsize = 0;
		u.u_ssize = rip->p_ssize = rpp->p_ssize;
		rip->p_saddr = rpp->p_saddr;
		rpp->p_ssize = 0;
		rip->p_textp = rpp->p_textp;
		rpp->p_textp = NULL;
		rpp->p_flag |= SVFDONE;
		wakeup((caddr_t)rip);
		/* must do estabur if dsize/ssize are different */
		estabur(u.u_tsize,u.u_dsize,u.u_ssize,u.u_sep,RO);
		rip->p_flag &= ~SVFPARENT;
	}
	return(0);

#else   VIRUS_VFORK
	rpp->p_size = n = rip->p_size;
	a1 = rip->p_addr;
#ifndef UCB_FRCSWAP
	a2 = malloc(coremap, n);
#else
	if(idleflg)
		a2 = malloc(coremap, n);
	else
		a2 = NULL;
#endif
	/*
	 * If there is not enough core for the
	 * new process, swap out the current process to generate the
	 * copy.
	 */
	if(a2 == NULL) {
		rip->p_stat = SIDL;
		rpp->p_addr = a1;
		rpp->p_stat = SRUN;
		(void) xswap(rpp, X_DONTFREE, X_OLDSIZE);
		rip->p_stat = SRUN;
#ifdef  CGL_RTP
		u.u_procp = rip; /* see comments below */
#endif
	} else {
		/*
		 * There is core, so just copy.
		 */
		rpp->p_addr = a2;
#ifdef  CGL_RTP
		/*
		 * Copy is now a preemptable kernel process.
		 * The u. area is non-reentrant so copy it first
		 * in non-preemptable mode.
		 */
		copyu(a2);
		/*
		 * If we are to be interrupted we must insure consistency;
		 * restore current process state now.
		 */
		u.u_procp = rip;
		copy(a1+USIZE, a2+USIZE, n-USIZE);
#else
		copy(a1, a2, n);
#endif
		(void) _spl6();
		rpp->p_stat = SRUN;
#ifdef SCHED
		setrq(rpp, 1);
#else
		SETRQ(rpp);
#endif SCHED
		(void) _spl0();
	}
#ifndef CGL_RTP
	u.u_procp = rip;
#endif
	rpp->p_flag |= SSWAP;
	return(0);
#endif  VIRUS_VFORK
}

#ifdef  VIRUS_VFORK
/*
 * Notify parent that vfork child is finished with parent's data.
 * Called during exit/exec(getxfile); must be called before xfree().
 * The child must be locked in core
 * so it will be in core when the parent runs.
 */
endvfork()
{
	register struct proc *rip, *rpp;

	rpp = u.u_procp;
	rip = rpp->p_pptr;
	rpp->p_flag &= ~SVFORK;
	rpp->p_flag |= SLOCK;
	wakeup((caddr_t)rpp);
	while(!(rpp->p_flag&SVFDONE))
		sleep((caddr_t)rip,PZERO-1);
	/*
	 * The parent has taken back our data+stack, set our sizes to 0.
	 */
	u.u_dsize = rpp->p_dsize = 0;
	u.u_ssize = rpp->p_ssize = 0;
	rpp->p_flag &= ~(SVFDONE | SLOCK);
}
#endif
/*
 * Change the size of the data+stack regions of the process.
 * If the size is shrinking, it's easy-- just release the extra core.
 * If it's growing, and there is core, just allocate it
 * and copy the image, taking care to reset registers to account
 * for the fact that the system's stack has moved.
 * If there is no core, arrange for the process to be swapped
 * out after adjusting the size requirement-- when it comes
 * in, enough core will be allocated.
 *
 * After the expansion, the caller will take care of copying
 * the user's stack towards or away from the data area.
 */
#ifdef  VIRUS_VFORK
/*
 * The data and stack segments are separated from each other.  The second
 * argument to expand specifies which to change.  The stack segment will
 * not have to be copied again after expansion.
 */
expand(newsize,segment)
#else
expand(newsize)
#endif
{
	register i,
		 n;     /* старый размер сегмента */
	register struct proc *p;
	register a1,    /* старый адрес сегмента */
		 a2;    /* новый (с новыми размерами) */

#ifdef  VIRUS_VFORK
	p = u.u_procp;
	if (segment == S_DATA) {
		n = p->p_dsize;
		p->p_dsize = newsize;
		a1 = p->p_daddr;
		/* сегмент уменьшается */
		if(n >= newsize) {
			n -= newsize;
			mfree(coremap, n, a1+newsize);
			return;
		}
	} else {
		n = p->p_ssize;
		p->p_ssize = newsize;
		a1 = p->p_saddr;
		if(n >= newsize) {
			n -= newsize;
			p->p_saddr += n;
			mfree(coremap, n, a1);
			/*
			 *  Since the base of stack is different,
			 *  segmentation registers must be repointed.
			 */
			sureg();
			return;
		}
	}

	/* сегмент растет */
	if (save(u.u_ssav)) {
		/*
		 * If we had to swap, the stack needs moving up.
		 */
		if (segment == S_STACK) {
			a1 = p->p_saddr;
			i = newsize - n;
			a2 = a1 + i;
			/*
			 * i is the amount of growth.  Copy i clicks
			 * at a time, from the top; do the remainder
			 * (n % i) separately.
			 */
			while (n >= i) {
				n -= i;
				copy(a1+n, a2+n, i);
			}
			copy(a1, a2, n);
		}
		sureg();
		return;
	}
#ifndef NONFP
	if (u.u_fpsaved==0) {
		savfp(&u.u_fps);
		u.u_fpsaved = 1;
	}
#endif
#ifdef  UCB_FRCSWAP
	/*
	 * Stack must be copied either way, might as well not swap.
	 */
	if(idleflg || (segment==S_STACK))
		a2 = malloc(coremap, newsize);
	else
		a2 = NULL;
#else
#ifdef IPK_MEXPAND
	if( segment == S_DATA ){
		a2 = mexpand( coremap, a1, n, newsize );
		if( a2 == a1 ){
			/* Сегмент просто расширился       */
			/* Никуда переписывать его не надо */
			sureg();
			return;
		}
		/* иначе mexpand сработал просто как malloc */
	}else
#endif IPK_MEXPAND
	a2 = malloc(coremap, newsize);
#endif
	if(a2 == NULL) {
		if (segment == S_DATA)
			(void) xswap(p, X_FREECORE, n, X_OLDSIZE);
		else
			(void) xswap(p, X_FREECORE, X_OLDSIZE, n);
		p->p_flag |= SSWAP;
		swtch();
		/* NOTREACHED */
	}
	if (segment == S_STACK) {
		p->p_saddr = a2;
		/*
		 * Make the copy put the stack at the top of the new area.
		 */
		a2 += newsize - n;
	} else
		p->p_daddr = a2;
	copy(a1, a2, n);
	mfree(coremap, n, a1);
	sureg();
	return;

#else   VIRUS_VFORK
	p = u.u_procp;
	n = p->p_size;
	p->p_size = newsize;
	a1 = p->p_addr;
	if(n >= newsize) {
		mfree(coremap, n-newsize, a1+newsize);
		return;
	}
	if (save(u.u_ssav)) {
		sureg();
		return;
	}
#ifndef NONFP
	if (u.u_fpsaved==0) {
		savfp(&u.u_fps);
		u.u_fpsaved = 1;
	}
#endif
#ifdef  UCB_FRCSWAP
	if(idleflg)
		a2 = malloc(coremap, newsize);
	else
		a2 = NULL;
#else
	a2 = malloc(coremap, newsize);
#endif
	if(a2 == NULL) {
		(void) xswap(p, X_FREECORE, n);
		p->p_flag |= SSWAP;
		swtch();
		/*NOTREACHED*/
	}
#ifdef  CGL_RTP
	copyu(a2);      /* see comments in newproc() */
	copy(a1+USIZE, a2+USIZE, n-USIZE);
	p->p_addr = a2;
#else
	p->p_addr = a2;
	copy(a1, a2, n);
#endif
	mfree(coremap, n, a1);
	resume(a2, u.u_ssav);
#endif  VIRUS_VFORK
}
#ifdef  CGL_RTP
/*
 * Test status of the "real time process";
 * preempt the current process if runnable.
 * Use caution when calling this routine, much
 * of the kernel is non-reentrant!
 */
runrtp()
{
	register struct proc *p;

	if ((p=rtpp)==NULL || p==u.u_procp)
		return;
	if (p->p_stat==SRUN && (p->p_flag&SLOAD)!=0) {
		u.u_procp->p_pri = PRTP+1;
		qswtch();
	}
}
#endif
@


22.2
log
@Правлена ошибка by korotaev (see diff 1.4 --> 1.5): 
дважды вызывался SETRQ.
Ошибка найдена при переносе на 8086.
@
text
@d2 6
a7 1
 * $Log:        slp.c,v $
d61 1
a61 1
#include <sys/map.h>
d64 1
a64 1
#include <sys/buf.h>
d69 1
a69 1
#include <sys/inline.h>
@


22.1
log
@"param.h" ==> <sys/param.h>
@
text
@d2 4
a5 1
 * $Log:	slp.c,v $
d8 1
a8 1
 * 
d11 1
a11 1
 * 
d14 1
a14 1
 * 
d16 1
a16 1
 * Изменен механизм расширения сегмента data. Если после него есть свободное 
d19 1
a19 1
 * 
a1286 1
		SETRQ(rpp);
@


22.0
log
@Begining DEMOS 2.2.
@
text
@d3 3
d47 1
a47 1
#include "param.h"
@


1.9
log
@в sleep добавлен флаг PCATCH a la systemV
@
text
@d3 3
@


1.8
log
@new malloc (mexpand)
@
text
@d3 3
d96 11
d113 1
d116 1
d165 1
a165 1
	return;
d175 5
@


1.7
log
@Слияние с исправлениями насчет FIFO, +fcntl, + разные режимы открытия

(from VAX/UTS SV.2)
@
text
@d3 10
d15 1
a15 1
 * 
d18 1
a18 1
 * 
d21 1
a21 1
 * 
d37 1
d64 3
a66 3
#define TTIINC		6	/* tty input increment */
#define TTOINC		4	/* tty output increment */
#define OTHINC		2	/* increment for other sleeps */
d255 1
a255 1
int flag;	/* if nonzero, insert at head */
d257 1
a257 1
	register struct proc *q, *ip;	/* ip is "insertion point" */
d277 1
a277 1
	if(ip == NULL){	/* insert at start of list */
d282 1
a282 1
		p->p_link = ip->p_link;	/* save rest of list */
d287 1
a287 1
		runrun++;	/* this line implements preemptive scheduling */
d469 1
a469 1
	for(;;){	/* keep loading processes !!! */
d485 1
a485 1
	
d487 1
a487 1
	
d491 1
a491 1
	
d688 1
a688 1
			return(0);	/* avoid swapping an EXECing proc */
d705 1
a705 1
			return(0);	/* avoid swapping an EXECing proc */
d829 1
a829 1
	register int f = 0;	/* setrq flag */
d836 1
a836 1
	else {			/* process preempted by higher level process */
d838 1
a838 1
		f++;	/* insert process at head of level subqueue */
d927 1
a927 1
		q = p;	/* update predecessor */
d976 1
a976 1
	if(p->p_quant > 0)	/* last quantum partially used */
d1318 2
a1319 1
	register i, n;
d1321 2
a1322 1
	register a1, a2;
d1330 1
d1352 2
d1391 12
@


1.6
log
@*** empty log message ***
@
text
@d3 3
a85 1
#ifdef  MENLO_JCL
a86 4
#else
	register h;
	struct proc *q;
#endif
d91 4
a94 4
#ifdef  MENLO_JCL
	if (chan==0
#ifndef SCHED
|| rp->p_stat != SRUN
a95 1
)
a96 7
#else
	if (chan==0)
		panic("sleep");
#ifndef SCHED
	rp->p_stat = SSLEEP;
#endif  SCHED
#endif
a103 1
#ifdef  MENLO_JCL
a106 17
#else
	h = HASH(chan);
#ifdef DIAGNOSTIC
	/*
	 * remove this diagnostic loop
	 * when you're sure it can't happen
	 */
	for(q=slpque[h]; q!=NULL; q=q->p_link)
		if(q == rp) {
			printf("proc asleep %d\n", rp->p_pid);
			goto cont;
		}
#endif
	rp->p_link = slpque[h];
	slpque[h] = rp;
cont:
#endif
a110 1
#ifdef  MENLO_JCL
a122 9
#else
		if(issig()) {
			rp->p_wchan = 0;
			rp->p_stat = SRUN;
			slpque[h] = rp->p_link;
			(void) _spl0();
			goto psig;
		}
#endif
a128 1
#ifdef  MENLO_JCL
a129 3
#else
		if(issig())
#endif
a131 1
#if defined(SCHED) || defined(MENLO_JCL)
a132 1
#endif
a135 1
#ifdef  MENLO_JCL
a136 1
#endif
a151 1
#ifdef  MENLO_JCL
a172 1
#endif
a307 1
#ifdef  MENLO_JCL
a335 1
#endif
a343 1
#ifdef  MENLO_JCL
a371 2
#else
	register caddr_t w;
a372 19
	if (p->p_stat==0 || p->p_stat==SZOMB)
		panic("setrun");
	/*
	 * The assignment to w is necessary because of
	 * race conditions. (Interrupt between test and use)
	 */
	if (w = p->p_wchan) {
		wakeup(w);
		return;
	}
	p->p_stat = SRUN;
#ifdef SCHED
	setlev(p,1);
	setrq(p,0);
#else
	setrq(p);
#endif  SCHED
#endif

a626 1
#ifdef  MENLO_JCL
a631 3
#else
		p->p_flag &= ~SLOAD;
#endif
a795 1
#ifdef  MENLO_JCL
a799 1
#endif
a1029 4
#ifndef MENLO_JCL
	rpp->p_stat = SRUN;
	rpp->p_flag = SLOAD;
#else
a1036 4
#endif
#ifdef  UCB_SUBM
	rpp->p_flag |= rip->p_flag & SSUBM;
#endif
a1119 1
#ifdef  MENLO_JCL
a1120 1
#endif
a1145 1
#ifdef  MENLO_JCL
a1151 1
#endif
a1155 5
#ifndef MENLO_JCL
#ifndef SCHED
	setrq(rpp);
#endif SCHED
#endif
a1211 1
#ifdef  MENLO_JCL
a1212 1
#endif
a1238 1
#ifdef  MENLO_JCL
a1247 1
#endif
a1251 9
#ifndef MENLO_JCL
	(void) _spl6();
#ifdef SCHED
	 setrq(rpp, 0);
#else
	SETRQ(rpp);
#endif SCHED
	(void) _spl0();
#endif
a1382 1
#ifdef  MENLO_JCL
a1383 3
#else
		qswtch();
#endif
a1428 1
#ifdef  MENLO_JCL
a1429 3
#else
		qswtch();
#endif
@


1.5
log
@Состояние после слияния с АЗЛК, Э-85 и Бурковским планировщиком
@
text
@d3 3
a498 4
#ifdef NEWSCH
	p = ((pp->p_cpu & 0377) / 16) + PUSER + pp->p_nice - NZERO-pp->p_ttyio;
	pp->p_ttyio = 0;
#else
a499 5
#endif
#ifdef NEWSCH
	if(p < PUSER)
		p = PUSER;
#endif
@


1.4
log
@Изменения приоритетов by alex.
@
text
@d2 4
a5 1
 * $Log:        slp.c,v $
d46 10
d91 5
a95 1
	if (chan==0 || rp->p_stat != SRUN)
d100 1
d102 1
d108 1
d110 1
d133 3
d146 1
d148 1
d171 1
a171 1
#ifdef  MENLO_JCL
d242 5
a246 1
		if (p->p_stat != SSLEEP && p->p_stat != SSTOP)
d254 5
a258 1
			if (p->p_stat == SSLEEP) {
d272 3
a274 1
#ifndef DIAGNOSTIC
a275 2
#else
#  define SETRQ(p) setrq(p)
d277 9
d287 39
d351 1
a352 1

d397 3
d412 4
d418 1
d434 4
d439 1
d449 1
d452 1
d459 26
d496 4
d501 5
d513 1
a513 1

d530 66
d727 8
d736 51
d879 1
d882 1
d885 3
d889 1
d900 15
d916 1
d997 6
a1003 1
	q = NULL;
d1022 1
d1030 6
d1040 1
d1045 14
d1060 1
d1131 7
d1139 3
a1144 2
	rpp->p_time = 0;
	rpp->p_cpu = 0;
d1243 1
d1245 1
d1249 3
d1253 1
d1255 1
d1345 3
d1349 2
d1359 3
d1363 1
@


1.3
log
@Правки под сохранение сегмента text в памяти после выкачки процесса.
+ введен параметр FXMETER для измерения эффекта от этого нововведения.
@
text
@d2 5
a6 1
 * $Log:	slp.c,v $
d8 1
a8 1
 * Убран spl6() из цикла по таблице процессов в 
d12 1
a12 1
 * 
d15 1
a15 1
 * 
a33 8
#ifdef FXMETER
int fxcount;
long fxblocks;
#define xmeter(x) if(x->x_ccount == 0 && x->x_caddr) fxcount++, fxblocks += (unsigned)(x->x_size+63)>>3;
#else
#define xmeter(x) /* */
#endif FXMETER

d40 1
a40 1
int	wantrtp;	/* Set when the real-time process is runnable */
d43 2
a44 2
#ifdef	SMALL
#define SQSIZE 010	/* Must be power of 2 */
d46 1
a46 1
#define SQSIZE 0100	/* Must be power of 2 */
d49 2
a50 2
#define HASH(x)	(( (int) x >> 5) & (SQSIZE-1))
struct	proc	*slpque[SQSIZE];
d67 1
a67 1
#ifdef	MENLO_JCL
d77 1
a77 1
#ifdef	MENLO_JCL
d86 1
a86 1
#ifdef	UCB_METER
d90 1
a90 1
#ifdef	MENLO_JCL
d96 1
d106 1
d112 1
a112 1
#ifdef	MENLO_JCL
d138 1
a138 1
#ifdef	MENLO_JCL
d145 1
a145 1
#ifdef	MENLO_JCL
d151 1
a151 1
#ifdef	MENLO_JCL
d169 1
a169 1
#ifdef	MENLO_JCL
d203 1
a203 1
#ifndef	NOKA5
d221 1
a221 1
#ifdef	UCB_METER
d232 1
a232 1
#ifndef	NOKA5
d237 7
d257 1
a257 1
#ifdef	DIAGNOSTIC
d271 1
a271 1
#ifdef	MENLO_JCL
d309 1
a309 1
#ifdef	MENLO_JCL
d317 1
a317 1
		unsleep(p);		/* e.g. when sending signals */
d328 1
a328 1
		setrq(p);
d347 1
a347 1
#ifdef	CGL_RTP
d398 1
d404 1
a404 1

d417 1
a417 1
#ifdef	VIRUS_VFORK
d429 1
a429 1
#ifdef	VIRUS_VFORK
d470 6
a475 2
#ifdef	VIRUS_VFORK
			if (maxsize < rp->p_dsize + rp->p_ssize) {
d477 1
a477 1
				maxsize = rp->p_dsize + rp->p_ssize;
d486 1
a486 1
#ifdef	CGL_RTP
d507 1
a507 1
#ifdef	MENLO_JCL
d516 1
a516 1
#ifdef	VIRUS_VFORK
d535 1
a535 1
#ifdef	VIRUS_VFORK
d544 1
a544 1
#ifdef	VIRUS_VFORK
d548 1
a548 1

d592 1
a592 1
#else	VIRUS_VFORK
d619 1
a619 1
#endif	VIRUS_VFORK
d621 1
a621 1
#ifdef	MENLO_JCL
d671 1
a671 1
#ifndef	NONFP
d692 1
a692 1
#ifdef	UCB_METER
d698 1
a698 1
#ifdef	CGL_RTP
d712 1
a712 1
			panic("rtp not found\n");	/* "cannot happen" */
d739 1
a739 1
#ifdef	UCB_FRCSWAP
d745 1
a745 1
#ifdef	CGL_RTP
d768 1
a768 1
#ifdef	VIRUS_VFORK
d777 1
a777 1
#ifdef	VIRUS_VFORK
d807 1
a807 1
#ifndef	MENLO_JCL
d819 1
a819 1
#ifdef	UCB_SUBM
d830 1
a830 1
#ifdef	UCB_METER
d844 1
a844 1
#ifdef	VIRUS_VFORK
d871 1
a871 1
#ifdef	VIRUS_VFORK
d883 1
a883 1
#ifdef	UCB_FRCSWAP
d897 1
a897 1
#ifdef	MENLO_JCL
d908 1
a908 1
#ifdef	CGL_RTP
d925 1
a925 1
#ifdef	MENLO_JCL
d928 1
a928 1
		setrq(rpp);
d932 1
a932 1
#ifndef	MENLO_JCL
d972 1
a972 1
#else	VIRUS_VFORK
d991 1
a991 1
#ifdef	MENLO_JCL
d996 1
a996 1
#ifdef	CGL_RTP
d1004 1
a1004 1
#ifdef	CGL_RTP
d1020 1
a1020 1
#ifdef	MENLO_JCL
d1023 1
a1023 1
		setrq(rpp);
d1027 1
a1027 1
#ifndef	CGL_RTP
d1030 1
a1030 1
#ifndef	MENLO_JCL
d1032 1
a1032 1
	setrq(rpp);
d1037 1
a1037 1
#endif	VIRUS_VFORK
d1040 1
a1040 1
#ifdef	VIRUS_VFORK
d1079 1
a1079 1
#ifdef	VIRUS_VFORK
d1094 1
a1094 1
#ifdef	VIRUS_VFORK
d1149 1
a1149 1
#ifdef	UCB_FRCSWAP
d1166 1
a1166 1
#ifdef	MENLO_JCL
d1186 1
a1186 1
#else	VIRUS_VFORK
d1205 1
a1205 1
#ifdef	UCB_FRCSWAP
d1216 1
a1216 1
#ifdef	MENLO_JCL
d1223 2
a1224 2
#ifdef	CGL_RTP
	copyu(a2);	/* see comments in newproc() */
d1233 1
a1233 1
#endif	VIRUS_VFORK
d1235 1
a1235 1
#ifdef	CGL_RTP
@


1.2
log
@Убран spl6() из цикла по таблице процессов в 
задаче подкачки. Это можно делать, так как если даже
и отработает wakeup во время поиска, ничего страшного
не случится.
@
text
@d3 6
d30 8
d544 2
a545 1
		if (xp->x_ccount == 0) {
d591 2
a592 1
		if (xp->x_ccount == 0) {
@


1.1
log
@Initial revision
@
text
@d2 4
a5 1
 * $Log$
d391 4
a394 1
	(void) _spl6();
d418 1
d421 1
a423 1
	(void) _spl0();
d439 1
a439 2

	(void) _spl6();
d475 1
a475 1
	(void) _spl0();
d502 1
@
